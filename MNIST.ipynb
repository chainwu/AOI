{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2528  128  128]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('train.csv')\n",
    "\n",
    "#df.plot.hist()\n",
    "labels= df.Label\n",
    "#print(labels)\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import plot_model, to_categorical\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import glob\n",
    "import imageio\n",
    "import numpy as np\n",
    "import os.path as path\n",
    "from datetime import datetime\n",
    "\n",
    "# Image processing\n",
    "IMAGE_PATH='train_images'\n",
    "\n",
    "image_input_files = sorted(glob.glob(path.join(IMAGE_PATH, '*.png')))\n",
    "images = [imageio.imread(im) for im in image_input_files]\n",
    "images = np.asarray(images)\n",
    "#images = images[..., None]\n",
    "n_images = len(image_input_files)\n",
    "\n",
    "#print(n_images)\n",
    "\n",
    "#images = images.reshape(,180,1500,3)\n",
    "image_size = np.asarray([images.shape[0], images.shape[1], images.shape[2]])\n",
    "print(image_size)\n",
    "#images = np.expand_dims(images,axis=0)\n",
    "#print(image_size)\n",
    "images = images/256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.65625   ]\n",
      "   [0.68359375]\n",
      "   [0.68359375]\n",
      "   ...\n",
      "   [0.55859375]\n",
      "   [0.609375  ]\n",
      "   [0.61328125]]\n",
      "\n",
      "  [[0.72265625]\n",
      "   [0.65625   ]\n",
      "   [0.6640625 ]\n",
      "   ...\n",
      "   [0.59765625]\n",
      "   [0.578125  ]\n",
      "   [0.5859375 ]]\n",
      "\n",
      "  [[0.65234375]\n",
      "   [0.69140625]\n",
      "   [0.66796875]\n",
      "   ...\n",
      "   [0.578125  ]\n",
      "   [0.56640625]\n",
      "   [0.54296875]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.63671875]\n",
      "   [0.65625   ]\n",
      "   [0.71875   ]\n",
      "   ...\n",
      "   [0.5546875 ]\n",
      "   [0.6015625 ]\n",
      "   [0.6484375 ]]\n",
      "\n",
      "  [[0.6640625 ]\n",
      "   [0.6796875 ]\n",
      "   [0.74609375]\n",
      "   ...\n",
      "   [0.51171875]\n",
      "   [0.57421875]\n",
      "   [0.58203125]]\n",
      "\n",
      "  [[0.66015625]\n",
      "   [0.66796875]\n",
      "   [0.7265625 ]\n",
      "   ...\n",
      "   [0.62109375]\n",
      "   [0.6015625 ]\n",
      "   [0.625     ]]]\n",
      "\n",
      "\n",
      " [[[0.765625  ]\n",
      "   [0.7578125 ]\n",
      "   [0.73828125]\n",
      "   ...\n",
      "   [0.765625  ]\n",
      "   [0.78125   ]\n",
      "   [0.7890625 ]]\n",
      "\n",
      "  [[0.76171875]\n",
      "   [0.7578125 ]\n",
      "   [0.73828125]\n",
      "   ...\n",
      "   [0.76171875]\n",
      "   [0.77734375]\n",
      "   [0.78125   ]]\n",
      "\n",
      "  [[0.75390625]\n",
      "   [0.75      ]\n",
      "   [0.734375  ]\n",
      "   ...\n",
      "   [0.74609375]\n",
      "   [0.76171875]\n",
      "   [0.765625  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.89453125]\n",
      "   [0.88671875]\n",
      "   [0.859375  ]\n",
      "   ...\n",
      "   [0.734375  ]\n",
      "   [0.73046875]\n",
      "   [0.7265625 ]]\n",
      "\n",
      "  [[0.8828125 ]\n",
      "   [0.875     ]\n",
      "   [0.84375   ]\n",
      "   ...\n",
      "   [0.72265625]\n",
      "   [0.71484375]\n",
      "   [0.71484375]]\n",
      "\n",
      "  [[0.8828125 ]\n",
      "   [0.87109375]\n",
      "   [0.83984375]\n",
      "   ...\n",
      "   [0.71875   ]\n",
      "   [0.7109375 ]\n",
      "   [0.7109375 ]]]\n",
      "\n",
      "\n",
      " [[[0.6640625 ]\n",
      "   [0.671875  ]\n",
      "   [0.68359375]\n",
      "   ...\n",
      "   [0.7734375 ]\n",
      "   [0.76171875]\n",
      "   [0.7578125 ]]\n",
      "\n",
      "  [[0.6640625 ]\n",
      "   [0.671875  ]\n",
      "   [0.68359375]\n",
      "   ...\n",
      "   [0.7734375 ]\n",
      "   [0.765625  ]\n",
      "   [0.76171875]]\n",
      "\n",
      "  [[0.66015625]\n",
      "   [0.66796875]\n",
      "   [0.68359375]\n",
      "   ...\n",
      "   [0.7734375 ]\n",
      "   [0.76953125]\n",
      "   [0.76953125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.8125    ]\n",
      "   [0.8125    ]\n",
      "   [0.8046875 ]\n",
      "   ...\n",
      "   [0.75390625]\n",
      "   [0.75      ]\n",
      "   [0.75      ]]\n",
      "\n",
      "  [[0.828125  ]\n",
      "   [0.828125  ]\n",
      "   [0.828125  ]\n",
      "   ...\n",
      "   [0.73828125]\n",
      "   [0.734375  ]\n",
      "   [0.73046875]]\n",
      "\n",
      "  [[0.8359375 ]\n",
      "   [0.8359375 ]\n",
      "   [0.83984375]\n",
      "   ...\n",
      "   [0.734375  ]\n",
      "   [0.7265625 ]\n",
      "   [0.72265625]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.8359375 ]\n",
      "   [0.828125  ]\n",
      "   [0.80859375]\n",
      "   ...\n",
      "   [0.703125  ]\n",
      "   [0.69921875]\n",
      "   [0.6953125 ]]\n",
      "\n",
      "  [[0.8359375 ]\n",
      "   [0.828125  ]\n",
      "   [0.80859375]\n",
      "   ...\n",
      "   [0.69921875]\n",
      "   [0.6953125 ]\n",
      "   [0.69140625]]\n",
      "\n",
      "  [[0.83203125]\n",
      "   [0.82421875]\n",
      "   [0.80859375]\n",
      "   ...\n",
      "   [0.69140625]\n",
      "   [0.6875    ]\n",
      "   [0.68359375]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.77734375]\n",
      "   [0.76953125]\n",
      "   [0.76171875]\n",
      "   ...\n",
      "   [0.75      ]\n",
      "   [0.73828125]\n",
      "   [0.734375  ]]\n",
      "\n",
      "  [[0.78125   ]\n",
      "   [0.77734375]\n",
      "   [0.765625  ]\n",
      "   ...\n",
      "   [0.734375  ]\n",
      "   [0.72265625]\n",
      "   [0.71875   ]]\n",
      "\n",
      "  [[0.78515625]\n",
      "   [0.77734375]\n",
      "   [0.76953125]\n",
      "   ...\n",
      "   [0.73046875]\n",
      "   [0.71875   ]\n",
      "   [0.7109375 ]]]\n",
      "\n",
      "\n",
      " [[[0.72265625]\n",
      "   [0.65625   ]\n",
      "   [0.63671875]\n",
      "   ...\n",
      "   [0.7109375 ]\n",
      "   [0.65234375]\n",
      "   [0.671875  ]]\n",
      "\n",
      "  [[0.68359375]\n",
      "   [0.66796875]\n",
      "   [0.6640625 ]\n",
      "   ...\n",
      "   [0.67578125]\n",
      "   [0.640625  ]\n",
      "   [0.7265625 ]]\n",
      "\n",
      "  [[0.67578125]\n",
      "   [0.6171875 ]\n",
      "   [0.640625  ]\n",
      "   ...\n",
      "   [0.62890625]\n",
      "   [0.609375  ]\n",
      "   [0.65234375]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.71484375]\n",
      "   [0.671875  ]\n",
      "   [0.6484375 ]\n",
      "   ...\n",
      "   [0.6640625 ]\n",
      "   [0.66796875]\n",
      "   [0.64453125]]\n",
      "\n",
      "  [[0.671875  ]\n",
      "   [0.66015625]\n",
      "   [0.6875    ]\n",
      "   ...\n",
      "   [0.65234375]\n",
      "   [0.65234375]\n",
      "   [0.64453125]]\n",
      "\n",
      "  [[0.63671875]\n",
      "   [0.63671875]\n",
      "   [0.62109375]\n",
      "   ...\n",
      "   [0.640625  ]\n",
      "   [0.6484375 ]\n",
      "   [0.62890625]]]\n",
      "\n",
      "\n",
      " [[[0.76171875]\n",
      "   [0.734375  ]\n",
      "   [0.73046875]\n",
      "   ...\n",
      "   [0.703125  ]\n",
      "   [0.734375  ]\n",
      "   [0.77734375]]\n",
      "\n",
      "  [[0.765625  ]\n",
      "   [0.6953125 ]\n",
      "   [0.69921875]\n",
      "   ...\n",
      "   [0.76171875]\n",
      "   [0.8515625 ]\n",
      "   [0.88671875]]\n",
      "\n",
      "  [[0.7421875 ]\n",
      "   [0.73046875]\n",
      "   [0.71484375]\n",
      "   ...\n",
      "   [0.80859375]\n",
      "   [0.859375  ]\n",
      "   [0.859375  ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.671875  ]\n",
      "   [0.72265625]\n",
      "   [0.67578125]\n",
      "   ...\n",
      "   [0.828125  ]\n",
      "   [0.8515625 ]\n",
      "   [0.82421875]]\n",
      "\n",
      "  [[0.59765625]\n",
      "   [0.66015625]\n",
      "   [0.66796875]\n",
      "   ...\n",
      "   [0.7890625 ]\n",
      "   [0.7734375 ]\n",
      "   [0.7734375 ]]\n",
      "\n",
      "  [[0.6171875 ]\n",
      "   [0.64453125]\n",
      "   [0.70703125]\n",
      "   ...\n",
      "   [0.7890625 ]\n",
      "   [0.73046875]\n",
      "   [0.75390625]]]]\n",
      "[[[[0.7265625 ]\n",
      "   [0.734375  ]\n",
      "   [0.75      ]\n",
      "   ...\n",
      "   [0.66796875]\n",
      "   [0.66015625]\n",
      "   [0.72265625]]\n",
      "\n",
      "  [[0.76953125]\n",
      "   [0.7890625 ]\n",
      "   [0.796875  ]\n",
      "   ...\n",
      "   [0.66015625]\n",
      "   [0.71484375]\n",
      "   [0.69140625]]\n",
      "\n",
      "  [[0.81640625]\n",
      "   [0.79296875]\n",
      "   [0.7890625 ]\n",
      "   ...\n",
      "   [0.75      ]\n",
      "   [0.7578125 ]\n",
      "   [0.8359375 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.69140625]\n",
      "   [0.73046875]\n",
      "   [0.83203125]\n",
      "   ...\n",
      "   [0.80859375]\n",
      "   [0.76171875]\n",
      "   [0.71875   ]]\n",
      "\n",
      "  [[0.7265625 ]\n",
      "   [0.7734375 ]\n",
      "   [0.7421875 ]\n",
      "   ...\n",
      "   [0.75390625]\n",
      "   [0.73046875]\n",
      "   [0.7265625 ]]\n",
      "\n",
      "  [[0.7421875 ]\n",
      "   [0.76953125]\n",
      "   [0.76171875]\n",
      "   ...\n",
      "   [0.69921875]\n",
      "   [0.75      ]\n",
      "   [0.7890625 ]]]\n",
      "\n",
      "\n",
      " [[[0.8125    ]\n",
      "   [0.78125   ]\n",
      "   [0.8203125 ]\n",
      "   ...\n",
      "   [0.60546875]\n",
      "   [0.61328125]\n",
      "   [0.6015625 ]]\n",
      "\n",
      "  [[0.77734375]\n",
      "   [0.80078125]\n",
      "   [0.8125    ]\n",
      "   ...\n",
      "   [0.609375  ]\n",
      "   [0.59375   ]\n",
      "   [0.625     ]]\n",
      "\n",
      "  [[0.8125    ]\n",
      "   [0.8515625 ]\n",
      "   [0.82421875]\n",
      "   ...\n",
      "   [0.6171875 ]\n",
      "   [0.62890625]\n",
      "   [0.64453125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.94140625]\n",
      "   [0.84375   ]\n",
      "   [0.828125  ]\n",
      "   ...\n",
      "   [0.58984375]\n",
      "   [0.5859375 ]\n",
      "   [0.61328125]]\n",
      "\n",
      "  [[0.90625   ]\n",
      "   [0.84765625]\n",
      "   [0.8671875 ]\n",
      "   ...\n",
      "   [0.58984375]\n",
      "   [0.56640625]\n",
      "   [0.56640625]]\n",
      "\n",
      "  [[0.8203125 ]\n",
      "   [0.83203125]\n",
      "   [0.890625  ]\n",
      "   ...\n",
      "   [0.59765625]\n",
      "   [0.6015625 ]\n",
      "   [0.6015625 ]]]\n",
      "\n",
      "\n",
      " [[[0.625     ]\n",
      "   [0.6171875 ]\n",
      "   [0.56640625]\n",
      "   ...\n",
      "   [0.74609375]\n",
      "   [0.72265625]\n",
      "   [0.73828125]]\n",
      "\n",
      "  [[0.5625    ]\n",
      "   [0.609375  ]\n",
      "   [0.59765625]\n",
      "   ...\n",
      "   [0.703125  ]\n",
      "   [0.75390625]\n",
      "   [0.78125   ]]\n",
      "\n",
      "  [[0.61328125]\n",
      "   [0.60546875]\n",
      "   [0.6328125 ]\n",
      "   ...\n",
      "   [0.7890625 ]\n",
      "   [0.8125    ]\n",
      "   [0.76171875]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.55859375]\n",
      "   [0.578125  ]\n",
      "   [0.57421875]\n",
      "   ...\n",
      "   [0.6171875 ]\n",
      "   [0.59375   ]\n",
      "   [0.625     ]]\n",
      "\n",
      "  [[0.6796875 ]\n",
      "   [0.65234375]\n",
      "   [0.66015625]\n",
      "   ...\n",
      "   [0.609375  ]\n",
      "   [0.62890625]\n",
      "   [0.68359375]]\n",
      "\n",
      "  [[0.609375  ]\n",
      "   [0.6171875 ]\n",
      "   [0.625     ]\n",
      "   ...\n",
      "   [0.66015625]\n",
      "   [0.66796875]\n",
      "   [0.6015625 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.63671875]\n",
      "   [0.64453125]\n",
      "   [0.6640625 ]\n",
      "   ...\n",
      "   [0.69921875]\n",
      "   [0.69140625]\n",
      "   [0.6875    ]]\n",
      "\n",
      "  [[0.64453125]\n",
      "   [0.65234375]\n",
      "   [0.671875  ]\n",
      "   ...\n",
      "   [0.70703125]\n",
      "   [0.703125  ]\n",
      "   [0.703125  ]]\n",
      "\n",
      "  [[0.66015625]\n",
      "   [0.66796875]\n",
      "   [0.6875    ]\n",
      "   ...\n",
      "   [0.73046875]\n",
      "   [0.73828125]\n",
      "   [0.7421875 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.71484375]\n",
      "   [0.7109375 ]\n",
      "   [0.703125  ]\n",
      "   ...\n",
      "   [0.76171875]\n",
      "   [0.76171875]\n",
      "   [0.76171875]]\n",
      "\n",
      "  [[0.70703125]\n",
      "   [0.703125  ]\n",
      "   [0.6953125 ]\n",
      "   ...\n",
      "   [0.7734375 ]\n",
      "   [0.78125   ]\n",
      "   [0.78515625]]\n",
      "\n",
      "  [[0.69921875]\n",
      "   [0.69921875]\n",
      "   [0.69140625]\n",
      "   ...\n",
      "   [0.78125   ]\n",
      "   [0.7890625 ]\n",
      "   [0.796875  ]]]\n",
      "\n",
      "\n",
      " [[[0.6796875 ]\n",
      "   [0.6875    ]\n",
      "   [0.70703125]\n",
      "   ...\n",
      "   [0.6953125 ]\n",
      "   [0.69921875]\n",
      "   [0.703125  ]]\n",
      "\n",
      "  [[0.6875    ]\n",
      "   [0.6953125 ]\n",
      "   [0.7109375 ]\n",
      "   ...\n",
      "   [0.69140625]\n",
      "   [0.69921875]\n",
      "   [0.703125  ]]\n",
      "\n",
      "  [[0.6953125 ]\n",
      "   [0.703125  ]\n",
      "   [0.71875   ]\n",
      "   ...\n",
      "   [0.69140625]\n",
      "   [0.69921875]\n",
      "   [0.69921875]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.80859375]\n",
      "   [0.80859375]\n",
      "   [0.8046875 ]\n",
      "   ...\n",
      "   [0.7265625 ]\n",
      "   [0.71484375]\n",
      "   [0.7109375 ]]\n",
      "\n",
      "  [[0.81640625]\n",
      "   [0.81640625]\n",
      "   [0.8125    ]\n",
      "   ...\n",
      "   [0.71875   ]\n",
      "   [0.70703125]\n",
      "   [0.69921875]]\n",
      "\n",
      "  [[0.8203125 ]\n",
      "   [0.8203125 ]\n",
      "   [0.81640625]\n",
      "   ...\n",
      "   [0.71484375]\n",
      "   [0.703125  ]\n",
      "   [0.6953125 ]]]\n",
      "\n",
      "\n",
      " [[[0.6015625 ]\n",
      "   [0.61328125]\n",
      "   [0.6484375 ]\n",
      "   ...\n",
      "   [0.47265625]\n",
      "   [0.43359375]\n",
      "   [0.4375    ]]\n",
      "\n",
      "  [[0.63671875]\n",
      "   [0.65625   ]\n",
      "   [0.63671875]\n",
      "   ...\n",
      "   [0.453125  ]\n",
      "   [0.44921875]\n",
      "   [0.42578125]]\n",
      "\n",
      "  [[0.57421875]\n",
      "   [0.58203125]\n",
      "   [0.58984375]\n",
      "   ...\n",
      "   [0.45703125]\n",
      "   [0.4375    ]\n",
      "   [0.4140625 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.5       ]\n",
      "   [0.51953125]\n",
      "   [0.51953125]\n",
      "   ...\n",
      "   [0.42578125]\n",
      "   [0.4765625 ]\n",
      "   [0.47265625]]\n",
      "\n",
      "  [[0.5078125 ]\n",
      "   [0.54296875]\n",
      "   [0.53125   ]\n",
      "   ...\n",
      "   [0.4296875 ]\n",
      "   [0.4296875 ]\n",
      "   [0.4375    ]]\n",
      "\n",
      "  [[0.49609375]\n",
      "   [0.48046875]\n",
      "   [0.53125   ]\n",
      "   ...\n",
      "   [0.4296875 ]\n",
      "   [0.43359375]\n",
      "   [0.4375    ]]]]\n",
      "[[0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0.]]\n",
      "[[0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "num_classes = 6\n",
    "img_rows = 128\n",
    "img_cols = 128\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(images, labels, test_size=0.30)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "    \n",
    "y_train=to_categorical(y_train, num_classes)\n",
    "y_test=to_categorical(y_test, num_classes)\n",
    "\n",
    "print(x_train)\n",
    "print(x_test)\n",
    "\n",
    "print(y_train)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 128, 128, 512)     1024      \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 128, 128, 512)     262656    \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128, 128, 512)     0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128, 128, 6)       3078      \n",
      "=================================================================\n",
      "Total params: 266,758\n",
      "Trainable params: 266,758\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_17 to have 4 dimensions, but got array with shape (1769, 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8a954399314f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                     verbose=1)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ana3/envs/py367/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ana3/envs/py367/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ana3/envs/py367/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_17 to have 4 dimensions, but got array with shape (1769, 6)"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(128,128,1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "batch_size=100\n",
    "epochs=50\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py367)",
   "language": "python",
   "name": "py367"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
